# Extremely Quantized Transformer
## Transformer 구현
<img src="/image/transformer-model-architecture.png" width="40%" height="40%" title="Transformer architecture"></img>
### Reference
* [Transformer 구현 main reference (IncredableAI)](http://incredible.ai/nlp/2020/02/29/Transformer/#27-scaled-dot-product-attention)
* [reinforceNLP-paul-hyun](https://paul-hyun.github.io/transformer-02/)
* [](https://catsirup.github.io/ai/2020/04/09/transformer-code.html)

* [dataset/main 구현: nn.Transformer와 torchtext로 Seq2Seq 모델링](https://tutorials.pytorch.kr/beginner/transformer_tutorial.html)
* [Torchtext로 언어번역하기](https://tutorials.pytorch.kr/beginner/torchtext_translation_tutorial.html)
* [SamLynnEvans_eval-제대로쓰진않음](https://github.com/SamLynnEvans/Transformer)

* [nn.Transformer 비교 + eval코드](https://github.com/eagle705/pytorch-transformer-chatbot)
* [eval 코드 참조](https://www.tensorflow.org/tutorials/text/transformer#evaluate)
